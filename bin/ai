#!/usr/bin/env bash
# PayReady AI Unified CLI - Single entry point for all AI operations
# Version: 3.0.0
# Date: September 18, 2025

set -euo pipefail

# Directories (set early)
PAYREADY_HOME="${PAYREADY_HOME:-$HOME/.payready}"
PAYREADY_BIN="$(dirname "$0")"
CONFIG_DIR="$HOME/.config/payready"

# Colours
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

# Logging functions (define early to avoid undefined function errors)
log() { echo -e "${GREEN}[AI]${NC} $*" >&2; }
error() { echo -e "${RED}[ERROR]${NC} $*" >&2; exit 1; }
debug() { [[ "${AI_DEBUG:-false}" == "true" ]] && echo -e "${CYAN}[DEBUG]${NC} $*" >&2 || true; }

# Python environment setup
if [[ -z "${VIRTUAL_ENV:-}" ]]; then
    if command -v pyenv >/dev/null 2>&1; then
        eval "$(pyenv init -)"
        py_version=$(pyenv versions --bare 2>/dev/null | awk '/^3\.11/{print; exit}')
        if [[ -n "$py_version" ]]; then
            pyenv shell "$py_version" >/dev/null 2>&1 || true
        else
            debug "pyenv detected but no 3.11 runtime installed"
        fi
    fi
fi

log_event() {
    local payload="$1"
    local log_path=".project/memory/cli.log.jsonl"
    mkdir -p "${log_path%/*}"
    printf '%s\n' "$payload" >> "$log_path"
}

record_error() {
    local rc="$1"
    local line="$2"
    local ts
    ts=$(date -Iseconds 2>/dev/null || date)
    log_event "{\"ts\":\"$ts\",\"event\":\"cli_error\",\"rc\":$rc,\"line\":$line}"
}

trap 'record_error $? $LINENO' ERR

load_env_file() {
    local file="$1"
    [[ -f "$file" ]] && source "$file"
}

get_secret() {
    local name="$1"
    local value
    value=$(python3 - "$name" <<'PY' 2>/dev/null || true
import sys
try:
    import keyring
except ModuleNotFoundError:
    sys.exit(0)

service = "payready"
name = sys.argv[1]
value = keyring.get_password(service, name)
if value:
    sys.stdout.write(value)
PY
)
    printf '%s' "$value"
}

load_local_env() {
    local local_env_file="$(dirname "$PAYREADY_BIN")/config/env.local"

    if [[ "${PAYREADY_TEST_MODE:-0}" == "1" ]]; then
        debug "PAYREADY_TEST_MODE=1 detected - loading $local_env_file"

        local pre_openrouter="${OPENROUTER_API_KEY-__unset__}"
        local pre_portkey="${PORTKEY_API_KEY-__unset__}"
        local pre_anthropic="${ANTHROPIC_API_KEY-__unset__}"
        local pre_openai="${OPENAI_API_KEY-__unset__}"
        local pre_vk="${PORTKEY_VK_OPENROUTER-__unset__}"
        local pre_virtual="${PORTKEY_VIRTUAL_KEY-__unset__}"

        load_env_file "$local_env_file"

        if [[ "$pre_openrouter" != "__unset__" && -n "$pre_openrouter" ]]; then
            export OPENROUTER_API_KEY="$pre_openrouter"
        fi
        if [[ "$pre_portkey" != "__unset__" && -n "$pre_portkey" ]]; then
            export PORTKEY_API_KEY="$pre_portkey"
        fi
        if [[ "$pre_anthropic" != "__unset__" && -n "$pre_anthropic" ]]; then
            export ANTHROPIC_API_KEY="$pre_anthropic"
        fi
        if [[ "$pre_openai" != "__unset__" && -n "$pre_openai" ]]; then
            export OPENAI_API_KEY="$pre_openai"
        fi
        if [[ "$pre_vk" != "__unset__" && -n "$pre_vk" ]]; then
            export PORTKEY_VK_OPENROUTER="$pre_vk"
        fi
        if [[ "$pre_virtual" != "__unset__" && -n "$pre_virtual" ]]; then
            export PORTKEY_VIRTUAL_KEY="$pre_virtual"
        fi

        export PAYREADY_ENV="local"
        export PAYREADY_OFFLINE_MODE="${PAYREADY_OFFLINE_MODE:-1}"
        export USE_PORTKEY="${USE_PORTKEY:-0}"
        export USE_MEMORY="${USE_MEMORY:-0}"
        export USE_CACHE="${USE_CACHE:-0}"

        for key in OPENROUTER_API_KEY PORTKEY_API_KEY ANTHROPIC_API_KEY OPENAI_API_KEY PORTKEY_VK_OPENROUTER PORTKEY_VIRTUAL_KEY; do
            if [[ -z "${!key:-}" ]]; then
                export "$key"="stub"
            fi
        done

        return
    fi

    if [[ "${PAYREADY_ENV:-}" == "local" ]] || [[ -f "$local_env_file" && -z "${PAYREADY_ENV:-}" ]]; then
        debug "Loading local development environment from $local_env_file"
        load_env_file "$local_env_file"
        export PAYREADY_ENV="${PAYREADY_ENV:-local}"
    fi
}

mkdir -p "$CONFIG_DIR"
set -a

# Load local development config first if applicable
load_local_env

# Load user config files
load_env_file "$CONFIG_DIR/env.core"
load_env_file "$CONFIG_DIR/env.services"
load_env_file "$CONFIG_DIR/env.llm"
for env_file in "$CONFIG_DIR"/env.*; do
    case "$env_file" in
        "$CONFIG_DIR/env.core"|"$CONFIG_DIR/env.services"|"$CONFIG_DIR/env.llm")
            ;;
        *)
            load_env_file "$env_file"
            ;;
    esac
done
set +a

if [[ -z "${PORTKEY_API_KEY:-}" ]]; then
    fetched_secret=$(get_secret PORTKEY_API_KEY || true)
    if [[ -n "$fetched_secret" ]]; then
        export PORTKEY_API_KEY="$fetched_secret"
    fi
fi

if [[ -z "${OPENROUTER_API_KEY:-}" ]]; then
    fetched_or=$(get_secret OPENROUTER_API_KEY || true)
    if [[ -n "$fetched_or" ]]; then
        export OPENROUTER_API_KEY="$fetched_or"
    fi
fi

validate_api_key_format() {
    local key="$1"
    [[ -z "$key" ]] && return 1
    
    # In offline mode, always accept any key silently
    if [[ "${PAYREADY_OFFLINE_MODE:-0}" == "1" ]]; then
        return 0
    fi
    
    case "$key" in
        sk-*|sk-ant-*|sk-or-*|pk-*|vk-*|gsk_*)
            return 0
            ;;
        *)
            log "Warning: API key may have invalid format: ${key:0:8}..."
            return 1
            ;;
    esac
}

validate_environment() {
    # In offline mode, skip all validation silently
    if [[ "${PAYREADY_OFFLINE_MODE:-0}" == "1" ]]; then
        debug "Running in offline mode - skipping API key validation"
        return 0
    fi

    local -a warnings=()
    local has_valid_key=false
    local valid_key=""

    # Check for valid keys
    for k in "${PORTKEY_API_KEY:-}" "${OPENROUTER_API_KEY:-}" "${OPENAI_API_KEY:-}" "${ANTHROPIC_API_KEY:-}"; do
        if [[ -n "$k" ]] && validate_api_key_format "$k"; then
            has_valid_key=true
            valid_key="$k"
            break
        fi
    done

    if [[ "$has_valid_key" == "false" ]]; then
        error "No valid API key found.\n\nTo configure, run:\n  ai config setup\nOr use:\n  keyring set payready OPENROUTER_API_KEY <your-key>\n  keyring set payready PORTKEY_API_KEY <your-key>\nSee: https://payready.ai/docs/GUIDES/SETUP_GUIDE.md"
    fi

    if [[ -n "${PORTKEY_API_KEY:-}" ]]; then
        has_valid_key=true
    fi

    if [[ -n "${OPENROUTER_API_KEY:-}" ]] && [[ "${OPENROUTER_API_KEY}" != *"YOUR_KEY"* ]]; then
        has_valid_key=true
    elif [[ -z "${PORTKEY_API_KEY:-}" ]]; then
        warnings+=("OPENROUTER_API_KEY not configured - fallback routing disabled")
    fi

    if [[ "$has_valid_key" == "false" ]]; then
        error "At least one valid API key required: PORTKEY_API_KEY or OPENROUTER_API_KEY"
    fi

    if [[ -z "${PORTKEY_API_KEY:-}" ]]; then
        warnings+=("PORTKEY_API_KEY not configured - using OpenRouter only")
    fi

    local use_portkey="${USE_PORTKEY:-}"
    use_portkey=$(printf '%s' "$use_portkey" | tr '[:upper:]' '[:lower:]')
    if [[ "$use_portkey" =~ ^(1|true|yes)$ ]]; then
        if [[ -z "${PORTKEY_VK_OPENROUTER:-}" && -z "${PORTKEY_VIRTUAL_KEY:-}" ]]; then
            warnings+=("USE_PORTKEY enabled but no virtual key configured (PORTKEY_VK_OPENROUTER / PORTKEY_VIRTUAL_KEY)")
        fi
    fi

    if (( ${#warnings[@]} )); then
        for warning in "${warnings[@]}"; do
            debug "$warning"
        done
    fi
}

# ============================================================================
# Authentication Management
# ============================================================================

get_auth_method() {
    # All models now use Portkey/OpenRouter routing
    echo "portkey"
}

get_virtual_key() {
    local intent="$1"

    # Return appropriate virtual key based on intent
    # Updated Sept 2025 with optimal provider mapping
    case "$intent" in
        code)
            echo "${PORTKEY_VK_OPENROUTER:-openrouter-vk}"
            ;;
        analyze)
            echo "${PORTKEY_VK_OPENROUTER:-openrouter-vk}"
            ;;
        design)
            echo "${PORTKEY_VK_OPENROUTER:-openrouter-vk}"
            ;;
        search)
            echo "${PORTKEY_VK_OPENROUTER:-openrouter-vk}"
            ;;
        fast)
            echo "${PORTKEY_VK_OPENROUTER:-openrouter-vk}"
            ;;
        deep)
            echo "${PORTKEY_VK_OPENROUTER:-openrouter-vk}"
            ;;
        *)
            echo "${PORTKEY_VK_OPENROUTER:-openrouter-vk}"
            ;;
    esac
}

# ============================================================================
# Model Selection
# ============================================================================

detect_intent() {
    local query="$1"
    # Portable lowercase conversion (works on BSD/macOS and GNU/Linux)
    local query_lower=$(echo "$query" | tr '[:upper:]' '[:lower:]')

    # Fast responses -> Groq
    if [[ "$query_lower" =~ (quick|fast|brief|simple|tldr) ]]; then
        echo "fast"
        return
    fi

    if [[ "$query_lower" =~ (solve|algorithm|math|proof|reason|complex) ]]; then
        echo "deep"
        return
    fi

    if [[ "$query_lower" =~ (design|architect|plan|system|integrate) ]]; then
        echo "design"
        return
    fi

    if [[ "$query_lower" =~ (analyze|review|audit|examine|understand|explain) ]]; then
        echo "analyze"
        return
    fi

    if [[ "$query_lower" =~ (search|latest|current|recent|news|2025) ]]; then
        echo "search"
        return
    fi

    if [[ "$query_lower" =~ (code|function|class|script|module) ]]; then
        echo "code"
        return
    fi

    echo "general"
}

select_models() {
    local intent="$1"

    case "$intent" in
        code|code_fast)
            echo "qwen/qwen3-coder-flash x-ai/grok-code-fast-1 openai/gpt-4.1-mini"
            ;;
        code_plus)
            echo "qwen/qwen3-coder-plus anthropic/claude-sonnet-4 anthropic/claude-opus-4.1"
            ;;
        analyze)
            echo "google/gemini-2.5-pro anthropic/claude-sonnet-4 openai/gpt-5-mini"
            ;;
        design)
            echo "openai/gpt-4.1-mini google/gemini-2.5-pro anthropic/claude-opus-4.1"
            ;;
        search)
            echo "google/gemini-2.5-flash openai/gpt-4.1-mini openai/gpt-5-mini"
            ;;
        fast)
            echo "openai/gpt-oss-120b google/gemini-2.5-flash openai/gpt-5-mini"
            ;;
        deep)
            echo "deepseek/deepseek-chat-v3-0324 anthropic/claude-opus-4.1 google/gemini-2.5-pro"
            ;;
        alt)
            echo "meta-llama/llama-4-maverick meta-llama/llama-4-scout openai/gpt-oss-120b"
            ;;
        general)
            echo "openai/gpt-5-mini anthropic/claude-sonnet-4 google/gemini-2.5-flash"
            ;;
        *)
            echo "openai/gpt-5-mini anthropic/claude-sonnet-4 google/gemini-2.5-flash"
            ;;
    esac
}

first_model() {
    local chain="$(select_models "$1")"
    printf '%s' "${chain%% *}"
}

# ============================================================================
# Request Execution
# ============================================================================


execute_portkey() {
    local query="$1"
    local vk="$2"
    shift 2
    local models=("$@")

    if [[ ${#models[@]} -eq 0 ]]; then
        error "No models available for intent"
    fi

    local escaped_query
    escaped_query=$(printf '%s' "$query" | jq -Rs .)
    local base_body
    base_body=$(cat <<EOF
{
    "messages": [{"role": "user", "content": $escaped_query}],
    "max_tokens": 2000
}
EOF
)

    local trace_id="${PAYREADY_TRACE_ID:-pr-$(uuidgen 2>/dev/null || date +%s)}"
    local portkey_config_default='{"retry":{"attempts":3,"on_status_codes":[408,429,500,502,503,504]}}'
    local portkey_config="${PORTKEY_CONFIG_JSON:-$portkey_config_default}"
    local portkey_timeout="${PORTKEY_REQUEST_TIMEOUT_MS:-8000}"
    local portkey_url="${PORTKEY_BASE_URL:-https://api.portkey.ai/v1}/chat/completions"
    local bypass_gateway="${PAYREADY_BYPASS_GATEWAY:-0}"

    if [[ "$bypass_gateway" != "1" && -n "${PORTKEY_API_KEY:-}" ]]; then
        local config_header trace_header timeout_header provider_header
        printf -v config_header 'x-portkey-config: %s' "$portkey_config"
        printf -v trace_header 'x-portkey-trace-id: %s' "$trace_id"
        printf -v timeout_header 'x-portkey-request-timeout: %s' "$portkey_timeout"
        provider_header='x-portkey-provider: openrouter'

        for model in "${models[@]}"; do
            [[ -z "$model" ]] && continue
            local request_body
            request_body=$(jq --arg model "$model" '.model = $model' <<<"$base_body")
            log "Using $model via Portkey..."
            local body_file
            body_file=$(mktemp)
            set +e
            local portkey_status
            portkey_status=$(curl -sS --fail-with-body \
                -o "$body_file" \
                -w '%{http_code}' \
                "$portkey_url" \
                -H "content-type: application/json" \
                -H "x-portkey-api-key: ${PORTKEY_API_KEY}" \
                -H "x-portkey-virtual-key: ${vk}" \
                -H "$provider_header" \
                -H "$timeout_header" \
                -H "$trace_header" \
                -H "$config_header" \
                -d "$request_body")
            local curl_exit=$?
            set -e

            if [[ $curl_exit -eq 0 && ${portkey_status:-0} -lt 400 ]]; then
                local response
                response=$(cat "$body_file")
                rm -f "$body_file"
                log_event "{\"ts\":\"$(date -Iseconds 2>/dev/null || date)\",\"event\":\"llm_request\",\"provider\":\"portkey\",\"model\":\"$model\",\"http_status\":${portkey_status},\"trace_id\":\"$trace_id\"}"
                [[ "${AI_DEBUG:-false}" == "true" ]] && echo "Portkey response: ${response:0:200}..." >&2
                echo "$response" | jq -r '.choices[0].message.content // .error.message // "Error: Invalid response"' 2>/dev/null || echo "Error: Failed to parse response"
                return 0
            fi

            debug "Portkey call failed (exit=${curl_exit}, status=${portkey_status:-n/a})"
            if [[ -s "$body_file" ]]; then
                debug "Portkey body: $(head -c 200 "$body_file")"
            fi
            rm -f "$body_file"
        done
    fi

    local fallback_model="${models[0]}"
    [[ -z "$fallback_model" ]] && fallback_model="openai/gpt-5-mini"
    local fallback_body
    fallback_body=$(jq --arg model "$fallback_model" '.model = $model' <<<"$base_body")

    if [[ -n "${OPENROUTER_API_KEY:-}" ]]; then
        log "Falling back to OpenRouter..."
        local or_file
        or_file=$(mktemp)
        set +e
        local openrouter_status
        openrouter_status=$(curl -sS --fail-with-body \
            -o "$or_file" \
            -w '%{http_code}' \
            https://openrouter.ai/api/v1/chat/completions \
            -H "authorization: Bearer ${OPENROUTER_API_KEY}" \
            -H "content-type: application/json" \
            -H "http-referer: ${OPENROUTER_REFERER:-https://payready.ai/tools}" \
            -H "x-title: ${OPENROUTER_TITLE:-PayReady CLI}" \
            -d "$fallback_body")
        local or_exit=$?
        set -e

        local response
        response=$(cat "$or_file")
        rm -f "$or_file"

        if [[ $or_exit -eq 0 && ${openrouter_status:-0} -lt 400 ]]; then
            log_event "{\"ts\":\"$(date -Iseconds 2>/dev/null || date)\",\"event\":\"llm_request\",\"provider\":\"openrouter\",\"model\":\"$fallback_model\",\"http_status\":${openrouter_status}}"
            [[ "${AI_DEBUG:-false}" == "true" ]] && echo "OpenRouter response: ${response:0:200}..." >&2
            echo "$response" | jq -r '.choices[0].message.content // .error.message // "Error: Invalid response"' 2>/dev/null || echo "Error: Failed to parse response"
            return 0
        fi

        debug "OpenRouter call failed (exit=${or_exit}, status=${openrouter_status:-n/a})"
        if [[ -n "$response" ]]; then
            debug "OpenRouter body: ${response:0:200}"
        fi
    fi

    return 1
}


# ============================================================================
# Main Execution
# ============================================================================

main() {
    local query=""
    local explicit_model=""
    local verbose=false
    local show_help=false

    # Validate environment for non-help commands
    if [[ "$*" != *"--help"* ]] && [[ "$*" != *"-h"* ]]; then
        validate_environment
    fi

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --model|-m)
                [[ -z "${2:-}" ]] && error "Model option requires a value"
                explicit_model="$2"
                shift 2
                ;;
            --verbose|-v)
                verbose=true
                AI_DEBUG=true
                shift
                ;;
            --help|-h)
                show_help=true
                shift
                ;;
            config|auth|test|doctor|remember|recall|memory)
                # Special commands
                handle_special_command "$@"
                exit 0
                ;;
            -*)
                error "Unknown option: $1"
                ;;
            *)
                query="$*"
                break
                ;;
        esac
    done

    # Show help if needed
    if [[ "$show_help" == "true" ]] || [[ -z "$query" ]]; then
        show_usage
        exit 0
    fi

    # Validate query length
    if [[ ${#query} -gt 4000 ]]; then
        error "Query too long (max 4000 characters)"
    fi

    # In offline mode, skip external tool validation
    if [[ "${PAYREADY_OFFLINE_MODE:-0}" != "1" ]]; then
        # Validate required tools (only when not in offline mode)
        command -v jq >/dev/null || error "jq is required but not installed"
        command -v curl >/dev/null || error "curl is required but not installed"
    fi

    # Detect intent and select model chain
    local intent
    intent=$(detect_intent "$query")

    local -a models
    if [[ -n "$explicit_model" ]]; then
        models=("$explicit_model")
    else
        IFS=' ' read -r -a models <<< "$(select_models "$intent")"
    fi

    if [[ ${#models[@]} -eq 0 ]]; then
        error "No models mapped for intent: $intent"
    fi

    debug "Intent: $intent"
    debug "Models: ${models[*]}"

    # Add context
    local context_query="$query (context: $(date +%Y-%m-%d), project: $(basename "$PWD"))"

    # In offline mode, return a helpful stub response
    if [[ "${PAYREADY_OFFLINE_MODE:-0}" == "1" ]]; then
        echo "🤖 PayReady AI (Offline Mode)"
        echo
        echo "Query: $query"
        echo "Intent: $intent"
        echo "Model: ${models[0]}"
        echo
        echo "This is a stub response for local development."
        echo "The system is running in offline mode without real API calls."
        echo "To use real AI models, configure API keys and disable offline mode."
        return 0
    fi

    # Execute via Portkey/OpenRouter
    local vk
    vk=$(get_virtual_key "$intent")
    debug "Virtual key: $vk"

    local response
    if ! response=$(execute_portkey "$context_query" "$vk" "${models[@]}"); then
        error "LLM request failed. Check Portkey/OpenRouter credentials or service status."
    fi

    echo "$response"

    # Log exchange to unified memory (best-effort)
    if [[ -n "$response" && -f "$PAYREADY_BIN/../core/unified_memory.py" ]]; then
        (
            if [[ -f .venv/bin/activate ]]; then
                source .venv/bin/activate
            fi
            export PYTHONPATH="$PAYREADY_BIN/..:$PYTHONPATH"
            python - "$context_query" "$response" "${models[0]}" <<'PY'
import sys
import time

try:
    from core.unified_memory import UnifiedMemory  # type: ignore
except Exception:
    raise SystemExit(0)

query, answer, model = sys.argv[1:4]

try:
    mem = UnifiedMemory()
    # Use the proper log_conversation method
    mem.log_conversation(query, answer, model)
except Exception:
    pass
PY
        ) || debug "Memory logging failed"
    fi
}

# ============================================================================
# Special Commands
# ============================================================================

handle_special_command() {
    local command="$1"
    shift

    case "$command" in
        config)
            handle_config "$@"
            ;;
        auth)
            handle_auth "$@"
            ;;
        test)
            run_tests "$@"
            ;;
        doctor)
            run_doctor
            ;;
        remember|recall|memory)
            handle_memory "$command" "$@"
            ;;
        *)
            error "Unknown command: $command"
            ;;
    esac
}

handle_config() {
    local action="${1:-list}"
    case "$action" in
        list)
            echo "Current Configuration:"
            echo "  PORTKEY_API_KEY: ${PORTKEY_API_KEY:0:10}..."
            echo "  OPENROUTER_API_KEY: ${OPENROUTER_API_KEY:0:10}..."
            echo "  Default Model: $(first_model 'general')"
            echo "  Debug Mode: ${AI_DEBUG:-false}"
            ;;
        set)
            local key="$2"
            local value="$3"
            echo "export $key='$value'" >> "$CONFIG_DIR/env.llm"
            log "Set $key"
            ;;
        setup)
            echo "PayReady AI Setup Wizard"
            echo "========================="
            read -p "Enter OpenRouter API key (or press Enter to skip): " or_key
            if [[ -n "$or_key" ]]; then
                python3 -c "import keyring; keyring.set_password('payready', 'OPENROUTER_API_KEY', '$or_key')"
                log "✓ OpenRouter key saved to keyring"
            fi
            read -p "Enter Portkey API key (or press Enter to skip): " pk_key
            if [[ -n "$pk_key" ]]; then
                python3 -c "import keyring; keyring.set_password('payready', 'PORTKEY_API_KEY', '$pk_key')"
                log "✓ Portkey key saved to keyring"
            fi
            read -p "Configure additional providers? (y/N): " more_keys
            if [[ "$more_keys" =~ ^[Yy]$ ]]; then
                read -p "Enter Anthropic API key (or press Enter to skip): " ant_key
                if [[ -n "$ant_key" ]]; then
                    python3 -c "import keyring; keyring.set_password('payready', 'ANTHROPIC_API_KEY', '$ant_key')"
                    log "✓ Anthropic key saved to keyring"
                fi
                read -p "Enter OpenAI API key (or press Enter to skip): " openai_key
                if [[ -n "$openai_key" ]]; then
                    python3 -c "import keyring; keyring.set_password('payready', 'OPENAI_API_KEY', '$openai_key')"
                    log "✓ OpenAI key saved to keyring"
                fi
            fi
            log "Setup complete. You may now use the CLI."
            ;;
        *)
            error "Unknown config action: $action"
            ;;
    esac
}

handle_auth() {
    local action="${1:-status}"

    case "$action" in
        status)
            echo "Authentication Status:"
            echo "  Portkey: $([ -n "${PORTKEY_API_KEY:-}" ] && echo "Configured" || echo "Not configured")"
            echo "  GPT-5 (ChatGPT): $([ -f ~/.codex/auth.json ] && echo "Logged in" || echo "Not logged in")"
            ;;
        login)
            log "Opening ChatGPT login for GPT-5-Codex access..."
            codex /login
            ;;
        *)
            error "Unknown auth action: $action"
            ;;
    esac
}

handle_memory() {
    local command="$1"
    shift

    # Use Python unified memory system
    export PYTHONPATH="$PAYREADY_BIN/..:$PYTHONPATH"

    case "$command" in
        remember)
            if [[ $# -lt 2 ]]; then
                error "Usage: ai remember <key> <value> [category]"
            fi
            (
                source .venv/bin/activate
                python3 - "$@" <<'PY'
import sys
from core.unified_memory import get_memory

if len(sys.argv) < 3:
    print("Usage: remember <key> <value> [category]")
    sys.exit(1)

key = sys.argv[1]
value = sys.argv[2]
category = sys.argv[3] if len(sys.argv) > 3 else "general"

mem = get_memory()
if mem.remember(key, value, category):
    print(f"Remembered: {key} -> {value} (category: {category})")
else:
    print("Failed to store memory")
PY
            )
            ;;
        recall)
            if [[ $# -lt 1 ]]; then
                error "Usage: ai recall <query> [category]"
            fi
            (
                source .venv/bin/activate
                python3 - "$@" <<'PY'
import sys
import json
from core.unified_memory import get_memory

if len(sys.argv) < 2:
    print("Usage: recall <query> [category]")
    sys.exit(1)

query = sys.argv[1]
category = sys.argv[2] if len(sys.argv) > 2 else None

mem = get_memory()
results = mem.recall(query, category, limit=5)

for r in results:
    print(f"[{r.get('source', 'unknown')}] {r.get('key', '')}: {r.get('value', '')}")
    if r.get('metadata'):
        print(f"  Metadata: {json.dumps(r.get('metadata'))}")
PY
            )
            ;;
        memory)
            local action="${1:-context}"
            case "$action" in
                context)
                    (
                        source .venv/bin/activate
                        python3 - <<'PY'
import json
from core.unified_memory import get_memory

mem = get_memory()
context = mem.get_context()

print(f"Memory Context:")
print(f"  Storage: {context.get('storage_type', 'unknown')}")
print(f"  Total memories: {context.get('stats', {}).get('total_memories', 0)}")
print(f"\nRecent conversations:")
for conv in context.get('conversations', [])[:3]:
    if isinstance(conv, dict):
        value = conv.get('value', {})
        if isinstance(value, dict):
            print(f"  - User: {value.get('user', '')[:80]}...")
            print(f"    AI: {value.get('assistant', '')[:80]}...")
PY
                    )
                    ;;
                *)
                    echo "Memory commands:"
                    echo "  ai remember <key> <value> [category]  - Store information"
                    echo "  ai recall <query> [category]          - Search memory"
                    echo "  ai memory context                     - Show current context"
                    ;;
            esac
            ;;
    esac
}

run_tests() {
    log "Running system tests..."

    # In offline mode, just show status
    if [[ "${PAYREADY_OFFLINE_MODE:-0}" == "1" ]]; then
        echo -e "${CYAN}Running in OFFLINE MODE${NC}"
        echo -e "Environment: ${GREEN}✓${NC}"
        echo -e "Config loaded: ${GREEN}✓${NC}"
        echo -e "Stub mode active: ${GREEN}✓${NC}"
        echo ""
        echo "All systems operational in offline mode."
        return 0
    fi

    # Test Portkey
    echo -n "Testing Portkey connection... "
    if curl -s -I https://api.portkey.ai/v1/models \
        -H "x-portkey-api-key: ${PORTKEY_API_KEY}" | grep -q "200"; then
        echo -e "${GREEN}✓${NC}"
    else
        echo -e "${RED}✗${NC}"
    fi

    # Test representative intents
    for intent in design analyze; do
        local model=$(first_model "$intent")
        local vk=$(get_virtual_key "$intent")
        echo -n "Testing $model... "
        local out
        if out=$(execute_portkey "Say 'OK'" "$vk" "$model" 2>/dev/null) && grep -qi "ok" <<<"$out"; then
            echo -e "${GREEN}✓${NC}"
        else
            echo -e "${RED}✗${NC}"
        fi
    done
}

run_doctor() {
    local intents=(code analyze design search fast deep general)

    if [[ -n "${PORTKEY_API_KEY:-}" ]]; then
        echo "Portkey Virtual Key checks:"
        for intent in "${intents[@]}"; do
            echo -n "  $intent → verifying... "
            local vk=$(get_virtual_key "$intent")
            local out
            out=$(execute_portkey "doctor ping" "$vk" $(select_models "$intent")) 2>&1
            local rc=$?
            if [[ $rc -eq 0 ]]; then
                echo -e "${GREEN}✓${NC}"
            else
                echo -e "${RED}✗${NC}"
                echo "    ${out}" | head -c 200
            fi
        done
    else
        echo -e "${YELLOW}!${NC} PORTKEY_API_KEY not set; skipping Portkey checks."
    fi

    if [[ -n "${OPENROUTER_API_KEY:-}" ]]; then
        echo "OpenRouter fallback check:"
        local tmp
        tmp=$(mktemp)
        set +e
        local or_status
        or_status=$(curl -sS --fail-with-body \
            -o "$tmp" \
            -w '%{http_code}' \
            https://openrouter.ai/api/v1/chat/completions \
            -H "authorization: Bearer ${OPENROUTER_API_KEY}" \
            -H "content-type: application/json" \
            -H "http-referer: ${OPENROUTER_REFERER:-https://payready.ai/tools}" \
            -H "x-title: ${OPENROUTER_TITLE:-PayReady CLI}" \
            -d '{"model":"openai/gpt-4.1-mini","messages":[{"role":"user","content":"ping"}]}')
        local or_exit=$?
        set -e
        if [[ $or_exit -eq 0 && ${or_status:-0} -lt 400 ]]; then
            echo -e "  ${GREEN}✓${NC} OpenRouter (HTTP $or_status)"
        else
            echo -e "  ${RED}✗${NC} OpenRouter (HTTP ${or_status:-n/a})"
            if [[ -s "$tmp" ]]; then
                echo "    $(head -c 120 "$tmp")"
            fi
        fi
        rm -f "$tmp"
    fi
}

# ============================================================================
# Usage Information
# ============================================================================

show_usage() {
    cat <<EOF
${GREEN}PayReady AI Unified CLI v3.0${NC}

${YELLOW}Usage:${NC}
    ai [options] <query>
    ai <command> [args]

${YELLOW}Options:${NC}
    --model, -m <model>   Use specific model
    --verbose, -v         Verbose output
    --help, -h           Show this help

${YELLOW}Commands:${NC}
    config list          Show configuration
    config set KEY VAL   Set configuration value
    config setup         Interactive setup wizard
    auth status          Show auth status
    auth login           Login to ChatGPT (for GPT-5)
    test                 Run system tests
    doctor               Validate Portkey/OpenRouter connectivity
    remember KEY VAL     Store information in memory
    recall QUERY         Search memory for information
    memory context       Show current memory context

${YELLOW}Examples:${NC}
    ai "write a hello world function"
    ai --model opus "analyze this codebase"
    ai --verbose "design a microservices architecture"

${YELLOW}Models (via Portkey/OpenRouter):${NC}
    x-ai/grok-code-fast-1           Grok Code Fast
    google/gemini-2.5-flash         Gemini 2.5 Flash
    google/gemini-2.5-pro          Gemini 2.5 Pro
    openai/gpt-4.1-mini            GPT-4.1 Mini
    openai/gpt-5-mini              GPT-5 Mini
    deepseek/deepseek-chat-v3-0324 DeepSeek Chat v3
    openai/gpt-oss-120b            GPT-OSS 120B
    meta-llama/llama-4-maverick    Llama 4 Maverick
    meta-llama/llama-4-scout       Llama 4 Scout
    qwen/qwen3-coder-flash         Qwen3 Coder Flash
    qwen/qwen3-coder-plus          Qwen3 Coder Plus
    anthropic/claude-opus-4.1      Claude Opus 4.1
    anthropic/claude-sonnet-4      Claude Sonnet 4

${CYAN}Pro tip:${NC} The CLI automatically selects the best model based on your query!
EOF
}

# ============================================================================
# Entry Point
# ============================================================================

main "$@"
